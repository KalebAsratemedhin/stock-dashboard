# Stock Dashboard

A **real-time analytics platform** that aggregates and visualizes four streams of business data: stock quotes, sales transactions, user events, and financial metrics. The system is built to demonstrate a production-style pipeline—message queues, time-series storage, pub/sub for live updates, and a browser UI that stays in sync without full reloads. All data is **synthetic**: generated by in-app services rather than external APIs, so the dashboard can run and demo end-to-end without API keys or external dependencies.

The backend is written in **Go** (API, worker, data simulator, migrations) and uses **TimescaleDB** for time-series storage, **RabbitMQ** for durable ingestion, and **Redis** for low-latency pub/sub. The frontend is a **Next.js** app (TypeScript, Tailwind, shadcn/ui, Recharts) that loads initial state via REST and then receives live updates over a single **WebSocket** connection, with client-side state held in **Zustand** stores.

---

## Architecture

High-level flow: **Simulator** produces records and publishes to **RabbitMQ** → **Worker** consumes, persists to **TimescaleDB**, and republishes to **Redis** → **API** serves REST and WebSocket; a **Redis bridge** inside the API subscribes to Redis and broadcasts to all WebSocket clients → **Frontend** fetches once, then updates in place from WebSocket messages.

```
    Data Simulator
           |
           | publish
           v
       RabbitMQ
           |
           | consume
           v
       Worker  ------- persist ------>  TimescaleDB
           |
           | publish
           v
       Redis
           |
           | subscribe
           v
    Redis Bridge  -->  WebSocket Hub  (inside API server)
           |
           | broadcast
           v
    Next.js App  <---- REST + WebSocket (initial load + live updates)
```

**Components in detail:**

- **Data Simulator** (`cmd/data-simulator`): Runs on fixed schedules (e.g. stock quotes every 30s, sales and user events on their own intervals). Generates synthetic records using in-memory generators (e.g. stock prices via a volatility model) and publishes JSON to RabbitMQ queues (one queue per data type). Can be configured with `SIMULATE_MARKET_HOURS=false` so stock data is produced 24/7.
- **RabbitMQ**: Holds four queues (stock_quotes, sales, user_events, financial_metrics). Decouples producers from the worker and allows backpressure and retries.
- **Worker** (`cmd/worker`): Consumes from each queue, deserializes payloads into domain models, validates and persists via the service/repository layers to TimescaleDB, then publishes the same payload to a corresponding Redis channel. Failures in DB write do not publish to Redis.
- **TimescaleDB**: PostgreSQL with the TimescaleDB extension. Hypertables partition data by time; migrations define schema and indexes. Used as the source of truth for historical and “latest” queries served by the API.
- **Redis**: Pub/sub only. One channel per data type. The worker publishes after each successful write; the API’s Redis bridge subscribes and forwards to the WebSocket hub.
- **API** (`cmd/api`): HTTP server with CORS, gzip, and logging. Serves REST routes for stocks, sales, events, and financial metrics (filtering, pagination, time ranges). Exposes a WebSocket at `/ws`; clients send subscription messages (e.g. `stock_quotes`). The Redis bridge receives Redis messages and broadcasts to all connected clients. No application state is stored in the API; it is a stateless gateway plus WebSocket broadcaster.
- **Frontend**: Next.js app with five main views (Dashboard, Market Intelligence, Sales Radar, User Behavior, Financial). On mount, pages request initial data from the REST API. A single WebSocket connection is shared; a `useWebSocket` hook subscribes to the channels needed per page and pushes incoming messages into Zustand stores. Components read from those stores, so new data appears without a full reload. Charts use Recharts; layout and UI use Tailwind and shadcn/ui.

---

## Dashboard Features

Each view shows a **Live** badge when the WebSocket is connected; data refreshes in place as new events arrive.

| Section | Description |
|--------|----------------|
| **Market Intelligence** | Scrollable symbol tabs; selected ticker header (price, change, NASDAQ badge, company name). Time-horizon (1D–MAX) and chart type (bar/line). Main chart: range bars (orange = up, white = down) or line, with EMA 20/50. **Live Matrix Watchlist** table: symbol, company, price, 24h change %, bid/ask spread, volume, mini sparkline; row click loads that symbol. |
| **Sales Radar** | Metric cards (revenue, net profit, avg order value). **Revenue vs Expenses** line chart. **Live Transactions** feed: recent sales with product, customer, time, amount. |
| **User Behavior** | Cards with event counts by type (Page View, Purchase, Login, etc.). **Live Terminal Logs** table: timestamp, event type, user id, page, country. |
| **Financial** | Metric cards (revenue, expenses, net profit, profit margin). **Budget vs Actual** table by department: actual, budget, variance, variance %. |
| **Dashboard (home)** | Executive overview: metric cards, **Market Performance** area chart, **Live Activity** feed of recent user events. |

---

## Tech Stack & Implementation

**Backend (Go)**  
- **API**: Handlers for stocks, sales, events, financial metrics (query params for symbol, range, limit, etc.). WebSocket upgrade and hub; Redis bridge subscribes and broadcasts. Middleware: CORS, gzip (skipped for `/ws`), request logging.  
- **Worker**: One consumer per RabbitMQ queue; unmarshal → service create → Redis publish. Shared DB, RabbitMQ, and Redis connections.  
- **Simulator**: Separate goroutines per data type with tickers; stock generator uses a volatility/mean-reversion model; sales, events, and financial use deterministic randomness.  
- **Data generator** (`cmd/data-generator`): Standalone program to backfill historical data into the DB (no RabbitMQ); useful for seeding before or instead of the simulator.  
- **Persistence**: GORM models; repository layer (CRUD, time-bucketed queries where needed); service layer (validation, defaults). Migrations are SQL (golang-migrate style) with hypertables and indexes.  

**Frontend (Next.js, TypeScript)**  
- **Pages**: Dashboard, Market Intelligence, Sales Radar, User Behavior, Financial; each wrapped in `Layout` (sidebar + main). Shared **PageHeader** (title, subtitle, Live badge).  
- **Components**: Reusable pieces (PageHeader, ChartContainer, EmptyState, MetricCard). Market Intelligence uses a dedicated set: StockSymbolTabs, StockQuoteHeader, StockChartControls, StockChart, StockWatchlistTable, MiniSparkline.  
- **State**: Zustand stores per domain (quotes, sales, events, financial); actions to set lists or append single items. **useWebSocket** manages connection, send-subscribe, and mapping of incoming messages to store actions.  
- **UI**: Tailwind CSS, shadcn/ui, Recharts; dark theme with orange accent.  

**Deployment**  
- **Docker**: Compose file in `backend/` defines TimescaleDB, RabbitMQ, Redis, API, worker, simulator. One multi-stage Dockerfile builds a single image with binaries for api, worker, simulator; Compose runs each with the appropriate command.  
- No shell scripts in the repo; start/stop/migrate are done via `docker compose` and `make` (see below).

---

## Quick Start

**Prerequisites:** Docker (and Docker Compose), Node.js 18+, npm.

1. **Start backend services** (from repo root):

   ```bash
   cd backend
   docker compose up -d --build
   ```

2. **Run database migrations** (with DB reachable; e.g. after Compose is up):

   ```bash
   cd backend
   make migrate-up
   ```

   If the `migrate` CLI is not installed: `go install -tags 'postgres' github.com/golang-migrate/migrate/v4/cmd/migrate@latest` and ensure `DB_URL` (or `DB_*` env) points at your DB. Default in Makefile: `postgres://postgres:postgres@localhost:5432/stock_dashboard?sslmode=disable`.

3. **Start the frontend**:

   ```bash
   cd client
   npm install
   npm run dev
   ```

- **App:** http://localhost:3000  
- **API:** http://localhost:8080  
- **RabbitMQ Management:** http://localhost:15672 (admin/admin)

**Stop backend:** From `backend/`, run `docker compose down`.

---

## Configuration

- **Backend:** Env in `backend/docker-compose.yml` or `backend/.env`: `DB_*`, `RABBITMQ_URL`, `REDIS_URL`, `API_PORT`. Optional: `SIMULATE_MARKET_HOURS=false` for 24/7 stock data from the simulator.  
- **Frontend:** `client/.env.local`: `NEXT_PUBLIC_API_URL`, `NEXT_PUBLIC_WS_URL` (defaults: http://localhost:8080, ws://localhost:8080).

---

## Commands Reference

| Where   | Command | Purpose |
|--------|---------|--------|
| Backend | `docker compose up -d --build` | Start all backend containers |
| Backend | `docker compose down` | Stop and remove containers |
| Backend | `make migrate-up` | Apply migrations (requires `migrate` CLI and `DB_URL`) |
| Backend | `make migrate` | Run migrations via Go program (`go run ./cmd/migrate`) |
| Backend | `make run-api` / `run-worker` / `run-simulator` / `run-generator` | Run API, worker, simulator, or data-generator locally |
| Backend | `make migrate-fresh` | Reset DB and re-run migrations (see Makefile) |
| Client  | `npm run dev` / `npm run build` | Dev server / production build |
